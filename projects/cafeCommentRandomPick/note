driver.driver.switch_to.frame('cafe_main')
html = driver.driver.page_source
soup = BeautifulSoup(html, 'html.parser')

for k in soup.find_all('ul', {'class': 'comment_list'}):
    for l in k.find_all('li'):
        print(l.attrs)


작성자
comment_nick_info.comment_nickname
 temp.find("a", {"aria-expanded":"false"}).string
작성자 id
comment_nick_info.id
 temp.find("div", {'class' : 'comment_nick_info'}).a['id']
댓글
 temp.find("span", {"class":"text_comment"}).string
print(temp.find("span", {'class' : 'text_comment'}))
text_comment
날짜
<span class="comment_info_date">2021.04.05. 18:13</span>
 temp.find("span", {"class":"comment_info_date"}).string
comment_info_date

#comment
 soup.find("strong", {"class":"num"}).string

#move tab
driver.driver.find_element_by_css_selector("#app > div > div > div.ArticleContentBox > div.article_container > div.CommentBox > div.ArticlePaginate > button:nth-child(2)").click()

𝟏 𝟐 𝟑 𝟒 𝟓 𝟔 𝟕 𝟖 𝟗 𝟎
🏵
🌸
🌫
CommentItem.comment_area.comment_thumb
						.comment_box.comment_nick_box.comment_nick_info.comment_nickname
									.comment_text_box.comment_text_view
													 .text_comment
									.comment_info_box.comment_info_date
									.comment_tool.comment_tool_button
									
									
app.Article.article_wrap.ArticleContentBox.article_container.CommentBox.ArticlePaginate									


#app > div > div > div.ArticleContentBox > div.article_container > div.CommentBox > div.ArticlePaginate > button:nth-child(2)
#app > div > div > div.ArticleContentBox > div.article_container > div.CommentBox > div.ArticlePaginate > button:nth-child(3)
#app > div > div > div.ArticleContentBox > div.article_container > div.CommentBox > div.ArticlePaginate > button:nth-child(4)
#app > div > div > div.ArticleContentBox > div.article_container > div.CommentBox > div.ArticlePaginate > button:nth-child(5)


#app > div > div > div.RelatedArticles > div.paginate_area > div > button:nth-child(2)


#\39 6680974
#\39 6680974
#cih96681134
//*[@id="96680974"]

self.driver.switch_to.frame("cafe_main")
self.driver.switch_to.frame("innerNetwork")
self.html = self.driver.page_source
self.soup = BeautifulSoup(self.html, "html.parser")
self.soup.find_all("td", {'class' : 'td_article'})

temp.find("div", {"class":"inner_number"}).string
temp.find("a").text.strip()

